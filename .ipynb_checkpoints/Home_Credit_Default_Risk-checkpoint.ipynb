{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9120,
          "databundleVersionId": 860599,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1004.850512,
      "end_time": "2024-12-01T01:10:43.772861",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-12-01T00:53:58.922349",
      "version": "2.6.0"
    },
    "colab": {
      "name": "Home Credit Default Risk",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "8lNjGExtPuim"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "home_credit_default_risk_path = kagglehub.competition_download('home-credit-default-risk')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "RAooA27kPuin",
        "outputId": "473eebdc-58fd-4b92-d27a-64df24af824d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-791f19ec-668e-45c9-9a15-23606e7eff39\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-791f19ec-668e-45c9-9a15-23606e7eff39\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f9541ec98d39>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Загрузка zip файла\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Указать путь к zip файлу\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Home Credit Default Risk Prediction"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.008134,
          "end_time": "2024-12-01T00:54:01.564032",
          "exception": false,
          "start_time": "2024-12-01T00:54:01.555898",
          "status": "completed"
        },
        "tags": [],
        "id": "d8bf341f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Project Overview**\n",
        "\n",
        "#### **The Challenge**\n",
        "For many people, getting approved for a loan is a major hurdle, especially if they don’t have a long credit history. Without a traditional credit score, many individuals find themselves shut out of mainstream banking, left with few choices but to turn to high-interest, often predatory lenders. This experience can trap people in a cycle of debt rather than helping them build a secure financial future. This project is all about changing that by exploring new, more inclusive ways to assess creditworthiness.\n",
        "\n",
        "#### **Home Credit's Mission**\n",
        "Home Credit believes everyone deserves a fair chance at financial stability. Instead of focusing only on traditional credit scores, they look at other indicators, like phone usage patterns and purchasing history, to better understand a person’s ability to repay a loan. By considering this alternative data, they aim to expand access to responsible loans for people who might otherwise be overlooked. At its core, this mission is about empowering underbanked communities with safer, more supportive financial options, giving people the tools to move forward with confidence and security.\n",
        "\n",
        "#### **Kaggle Challenge**\n",
        "To make this vision a reality, Home Credit has invited the Kaggle community to join forces in developing smarter models for assessing loan risks. The challenge here is to build a predictive model that can help Home Credit understand borrowers more deeply, identifying those who can handle a loan responsibly and tailoring solutions to fit their needs. For data scientists, it’s a chance to apply creativity and skill in a meaningful way—one that could make loans more accessible, fair, and geared toward long-term financial health. Participants will not only help improve Home Credit’s systems but also contribute to a financial system that serves more people, giving them the support they need to succeed."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.006861,
          "end_time": "2024-12-01T00:54:01.579748",
          "exception": false,
          "start_time": "2024-12-01T00:54:01.572887",
          "status": "completed"
        },
        "tags": [],
        "id": "dda7d0a9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Load Necessary Libraries**"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.007033,
          "end_time": "2024-12-01T00:54:01.594095",
          "exception": false,
          "start_time": "2024-12-01T00:54:01.587062",
          "status": "completed"
        },
        "tags": [],
        "id": "415e1444"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "default_dir = \"../input/home-credit-default-risk/\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:25:24.54943Z",
          "iopub.execute_input": "2024-12-15T18:25:24.549679Z",
          "iopub.status.idle": "2024-12-15T18:25:26.003112Z",
          "shell.execute_reply.started": "2024-12-15T18:25:24.549653Z",
          "shell.execute_reply": "2024-12-15T18:25:26.002129Z"
        },
        "papermill": {
          "duration": 2.515105,
          "end_time": "2024-12-01T00:54:04.116183",
          "exception": false,
          "start_time": "2024-12-01T00:54:01.601078",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "24364de9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: Load the Datasets**\n",
        "Use `pandas` to load the datasets:"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.006781,
          "end_time": "2024-12-01T00:54:04.130543",
          "exception": false,
          "start_time": "2024-12-01T00:54:04.123762",
          "status": "completed"
        },
        "tags": [],
        "id": "0cf2db00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Overview**\n",
        "\n",
        "**About the Dataset and Why It Matters:**  \n",
        "This dataset is provided by Home Credit, a lending company with a mission to serve people who may not have easy access to traditional banks. The goal here is to predict whether a client will successfully repay a loan, which is a big question for the business—it helps them make responsible lending choices and support clients fairly. Home Credit has shared this data on Kaggle, encouraging people around the world to contribute their machine learning skills and insights to help tackle this challenge.\n",
        "\n",
        "**What’s Inside the Dataset:**  \n",
        "The data comes from seven different files, each capturing unique but connected details about loan applications, past credit history, and payment behaviors. Together, these files create a detailed, 360-degree view of each client’s borrowing and repayment patterns, which is key to building accurate prediction models.\n",
        "\n",
        "1. **application_train/application_test**  \n",
        "   - **What It Contains:** This is the main file, recording every loan application to Home Credit.\n",
        "   - **How It Works:** Each row is a single loan application, identified by `SK_ID_CURR`.\n",
        "   - **What’s Special Here:** The `TARGET` column in `application_train` shows whether a loan was paid back (0 = repaid, 1 = not repaid). This column is not in `application_test`, as that file is used for testing the model's accuracy.\n",
        "   - **What It Covers:** Information about each applicant’s financial profile, like income, employment type, and loan details. These are crucial for the model to learn patterns related to loan repayment.\n",
        "\n",
        "2. **bureau**  \n",
        "   - **What It Contains:** This file gives insight into loans that clients held with other banks and lenders.\n",
        "   - **How It Works:** Each entry represents a past credit from a different lender and is linked to the main application data by `SK_ID_CURR`.\n",
        "   - **What It Covers:** Details like credit amount, type, and status, showing how clients have handled past loans with other institutions.\n",
        "\n",
        "3. **bureau_balance**  \n",
        "   - **What It Contains:** Monthly updates on each previous credit found in the `bureau` data.\n",
        "   - **How It Works:** Each row captures one month of data on a past credit, allowing us to see how long each credit lasted and track its repayment.\n",
        "   - **What It Covers:** Information like the status of each credit month-by-month, revealing the consistency or changes in payment behavior.\n",
        "\n",
        "4. **previous_application**  \n",
        "   - **What It Contains:** Records of past loan applications clients made with Home Credit.\n",
        "   - **How It Works:** Each previous application has its own identifier, `SK_ID_PREV`, making it possible to connect these with current applications.\n",
        "   - **What It Covers:** Factors such as loan amount, terms, and approval status, giving context on the client’s history with Home Credit.\n",
        "\n",
        "5. **POS_CASH_BALANCE**  \n",
        "   - **What It Contains:** Monthly records of point-of-sale (POS) or cash loans taken with Home Credit.\n",
        "   - **How It Works:** Each row represents one month of a POS or cash loan, allowing us to follow the loan’s progress.\n",
        "   - **What It Covers:** Monthly balance and loan status data, which lets us see how each loan evolved over time.\n",
        "\n",
        "6. **credit_card_balance**  \n",
        "   - **What It Contains:** Monthly information about credit card accounts clients previously held with Home Credit.\n",
        "   - **How It Works:** Each row represents a month’s snapshot of a credit card balance, helping track spending and repayment patterns over time.\n",
        "   - **What It Covers:** Monthly balances and payments for each credit card, which is great for understanding a client’s credit card usage and habits.\n",
        "\n",
        "7. **installments_payments**  \n",
        "   - **What It Contains:** This file tracks individual payments made on past loans with Home Credit.\n",
        "   - **How It Works:** Each entry captures a single payment, whether it was made on time, late, or missed.\n",
        "   - **What It Covers:** Information about payment timing and amount, shedding light on each client’s payment reliability.\n",
        "\n",
        "Together, these files give us a well-rounded picture of each client’s financial life, showing not just if they paid back loans but also how they manage their finances over time. By learning from these details, we can develop models that predict loan repayment more accurately, supporting responsible lending practices and opening doors for people who might otherwise struggle to access credit.\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.006807,
          "end_time": "2024-12-01T00:54:04.14445",
          "exception": false,
          "start_time": "2024-12-01T00:54:04.137643",
          "status": "completed"
        },
        "tags": [],
        "id": "3527acde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app_train = pd.read_csv(os.path.join(default_dir,'application_train.csv'))\n",
        "app_test = pd.read_csv(os.path.join(default_dir,'application_test.csv'))\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Training set shape:\", app_train.shape)\n",
        "print(\"Testing set shape:\", app_test.shape)\n",
        "\n",
        "app_test.head()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:25:26.005361Z",
          "iopub.execute_input": "2024-12-15T18:25:26.005865Z",
          "iopub.status.idle": "2024-12-15T18:25:31.982662Z",
          "shell.execute_reply.started": "2024-12-15T18:25:26.005823Z",
          "shell.execute_reply": "2024-12-15T18:25:31.981764Z"
        },
        "papermill": {
          "duration": 5.978102,
          "end_time": "2024-12-01T00:54:10.129657",
          "exception": false,
          "start_time": "2024-12-01T00:54:04.151555",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "8b743128"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_balance_data():\n",
        "    pos_dtype = {\n",
        "        'SK_ID_PREV':np.uint32, 'SK_ID_CURR':np.uint32, 'MONTHS_BALANCE':np.int32, 'SK_DPD':np.int32,\n",
        "        'SK_DPD_DEF':np.int32, 'CNT_INSTALMENT':np.float32,'CNT_INSTALMENT_FUTURE':np.float32\n",
        "    }\n",
        "\n",
        "    install_dtype = {\n",
        "        'SK_ID_PREV':np.uint32, 'SK_ID_CURR':np.uint32, 'NUM_INSTALMENT_NUMBER':np.int32, 'NUM_INSTALMENT_VERSION':np.float32,\n",
        "        'DAYS_INSTALMENT':np.float32, 'DAYS_ENTRY_PAYMENT':np.float32, 'AMT_INSTALMENT':np.float32, 'AMT_PAYMENT':np.float32\n",
        "    }\n",
        "\n",
        "    card_dtype = {\n",
        "        'SK_ID_PREV':np.uint32, 'SK_ID_CURR':np.uint32, 'MONTHS_BALANCE':np.int16,\n",
        "        'AMT_CREDIT_LIMIT_ACTUAL':np.int32, 'CNT_DRAWINGS_CURRENT':np.int32, 'SK_DPD':np.int32,'SK_DPD_DEF':np.int32,\n",
        "        'AMT_BALANCE':np.float32, 'AMT_DRAWINGS_ATM_CURRENT':np.float32, 'AMT_DRAWINGS_CURRENT':np.float32,\n",
        "        'AMT_DRAWINGS_OTHER_CURRENT':np.float32, 'AMT_DRAWINGS_POS_CURRENT':np.float32, 'AMT_INST_MIN_REGULARITY':np.float32,\n",
        "        'AMT_PAYMENT_CURRENT':np.float32, 'AMT_PAYMENT_TOTAL_CURRENT':np.float32, 'AMT_RECEIVABLE_PRINCIPAL':np.float32,\n",
        "        'AMT_RECIVABLE':np.float32, 'AMT_TOTAL_RECEIVABLE':np.float32, 'CNT_DRAWINGS_ATM_CURRENT':np.float32,\n",
        "        'CNT_DRAWINGS_OTHER_CURRENT':np.float32, 'CNT_DRAWINGS_POS_CURRENT':np.float32, 'CNT_INSTALMENT_MATURE_CUM':np.float32\n",
        "    }\n",
        "\n",
        "    pos_bal = pd.read_csv(os.path.join(default_dir,'POS_CASH_balance.csv'), dtype=pos_dtype)\n",
        "    install = pd.read_csv(os.path.join(default_dir,'installments_payments.csv'), dtype=install_dtype)\n",
        "    card_bal = pd.read_csv(os.path.join(default_dir, 'credit_card_balance.csv'), dtype=card_dtype)\n",
        "\n",
        "    return pos_bal, install, card_bal\n",
        "\n",
        "pos_bal, install, card_bal = get_balance_data()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:25:31.983751Z",
          "iopub.execute_input": "2024-12-15T18:25:31.984104Z",
          "iopub.status.idle": "2024-12-15T18:26:16.311142Z",
          "shell.execute_reply.started": "2024-12-15T18:25:31.984065Z",
          "shell.execute_reply": "2024-12-15T18:26:16.310255Z"
        },
        "papermill": {
          "duration": 43.734619,
          "end_time": "2024-12-01T00:54:53.872491",
          "exception": false,
          "start_time": "2024-12-01T00:54:10.137872",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "a8e4c3c0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate missing values\n",
        "def missing_values_table(df):\n",
        "        mis_val = df.isnull().sum()\n",
        "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "        mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
        "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1)\n",
        "\n",
        "        return mis_val_table_ren_columns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:16.312731Z",
          "iopub.execute_input": "2024-12-15T18:26:16.313149Z",
          "iopub.status.idle": "2024-12-15T18:26:16.320257Z",
          "shell.execute_reply.started": "2024-12-15T18:26:16.313106Z",
          "shell.execute_reply": "2024-12-15T18:26:16.319182Z"
        },
        "papermill": {
          "duration": 0.01602,
          "end_time": "2024-12-01T00:54:53.896673",
          "exception": false,
          "start_time": "2024-12-01T00:54:53.880653",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "418a764a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = missing_values_table(app_train)\n",
        "missing_values.head(20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:16.32149Z",
          "iopub.execute_input": "2024-12-15T18:26:16.321828Z",
          "iopub.status.idle": "2024-12-15T18:26:16.780626Z",
          "shell.execute_reply.started": "2024-12-15T18:26:16.321793Z",
          "shell.execute_reply": "2024-12-15T18:26:16.779694Z"
        },
        "papermill": {
          "duration": 0.484377,
          "end_time": "2024-12-01T00:54:54.38871",
          "exception": false,
          "start_time": "2024-12-01T00:54:53.904333",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "ae0300f1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Column types\n",
        "app_train.dtypes.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:16.781654Z",
          "iopub.execute_input": "2024-12-15T18:26:16.781905Z",
          "iopub.status.idle": "2024-12-15T18:26:16.790134Z",
          "shell.execute_reply.started": "2024-12-15T18:26:16.78188Z",
          "shell.execute_reply": "2024-12-15T18:26:16.789295Z"
        },
        "papermill": {
          "duration": 0.020396,
          "end_time": "2024-12-01T00:54:54.417032",
          "exception": false,
          "start_time": "2024-12-01T00:54:54.396636",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "a0db239a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# get object-type columns\n",
        "app_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:16.793047Z",
          "iopub.execute_input": "2024-12-15T18:26:16.79375Z",
          "iopub.status.idle": "2024-12-15T18:26:17.031073Z",
          "shell.execute_reply.started": "2024-12-15T18:26:16.793722Z",
          "shell.execute_reply": "2024-12-15T18:26:17.030167Z"
        },
        "papermill": {
          "duration": 0.264009,
          "end_time": "2024-12-01T00:54:54.688994",
          "exception": false,
          "start_time": "2024-12-01T00:54:54.424985",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "d5db40d9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder() # label encoder object\n",
        "le_count = 0\n",
        "\n",
        "for col in app_train:\n",
        "    if app_train[col].dtype == 'object':\n",
        "        if len(list(app_train[col].unique())) <= 2:\n",
        "            le.fit(app_train[col])\n",
        "            app_train[col] = le.transform(app_train[col])\n",
        "            app_test[col] = le.transform(app_test[col])\n",
        "\n",
        "            le_count += 1\n",
        "\n",
        "print(f\"Number of label-encoded columns: {le_count}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:17.032258Z",
          "iopub.execute_input": "2024-12-15T18:26:17.032636Z",
          "iopub.status.idle": "2024-12-15T18:26:17.386694Z",
          "shell.execute_reply.started": "2024-12-15T18:26:17.032606Z",
          "shell.execute_reply": "2024-12-15T18:26:17.386022Z"
        },
        "papermill": {
          "duration": 0.386549,
          "end_time": "2024-12-01T00:54:55.083571",
          "exception": false,
          "start_time": "2024-12-01T00:54:54.697022",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "63dc8d09"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding\n",
        "app_train = pd.get_dummies(app_train)\n",
        "app_test = pd.get_dummies(app_test)\n",
        "\n",
        "print('Training Features shape: ', app_train.shape)\n",
        "print('Testing Features shape: ', app_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:17.387686Z",
          "iopub.execute_input": "2024-12-15T18:26:17.387918Z",
          "iopub.status.idle": "2024-12-15T18:26:17.990916Z",
          "shell.execute_reply.started": "2024-12-15T18:26:17.387894Z",
          "shell.execute_reply": "2024-12-15T18:26:17.990028Z"
        },
        "papermill": {
          "duration": 0.745679,
          "end_time": "2024-12-01T00:54:55.837564",
          "exception": false,
          "start_time": "2024-12-01T00:54:55.091885",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "3e9d7cf5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3: Preprocess the Data**\n",
        "Follow the preprocessing steps as in the original notebook:\n",
        "1. Impute missing values.\n",
        "2. Scale numerical features.\n",
        "3. Split data into training and validation sets.:"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.007821,
          "end_time": "2024-12-01T00:54:55.854728",
          "exception": false,
          "start_time": "2024-12-01T00:54:55.846907",
          "status": "completed"
        },
        "tags": [],
        "id": "65331e97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = app_train['TARGET']\n",
        "\n",
        "# align test and train columns, hence \"inner\"\n",
        "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
        "\n",
        "# adding the target back in\n",
        "app_train['TARGET'] = train_labels\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:17.991988Z",
          "iopub.execute_input": "2024-12-15T18:26:17.992253Z",
          "iopub.status.idle": "2024-12-15T18:26:18.107333Z",
          "shell.execute_reply.started": "2024-12-15T18:26:17.992212Z",
          "shell.execute_reply": "2024-12-15T18:26:18.106406Z"
        },
        "papermill": {
          "duration": 0.137706,
          "end_time": "2024-12-01T00:54:56.000639",
          "exception": false,
          "start_time": "2024-12-01T00:54:55.862933",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "3d678935"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "app_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram')\n",
        "app_test['DAYS_EMPLOYED'].plot.hist()\n",
        "plt.xlabel('Days Employment')\n",
        "\n",
        "app_test['DAYS_EMPLOYED'][app_test['DAYS_EMPLOYED'] > 200000]\n",
        "\n",
        "# understand the anomolies\n",
        "anom = app_train[app_train['DAYS_EMPLOYED'] == 365243]\n",
        "non_anom = app_train[app_train['DAYS_EMPLOYED'] != 365243]\n",
        "print('The non-anomalies default on %0.2f%% of loans' % (100 * non_anom['TARGET'].mean()))\n",
        "print('The anomalies default on %0.2f%% of loans' % (100 * anom['TARGET'].mean()))\n",
        "print('There are %d anomalous days of employment' % len(anom))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:18.108437Z",
          "iopub.execute_input": "2024-12-15T18:26:18.108689Z",
          "iopub.status.idle": "2024-12-15T18:26:18.546587Z",
          "shell.execute_reply.started": "2024-12-15T18:26:18.108665Z",
          "shell.execute_reply": "2024-12-15T18:26:18.545756Z"
        },
        "papermill": {
          "duration": 0.538491,
          "end_time": "2024-12-01T00:54:56.548071",
          "exception": false,
          "start_time": "2024-12-01T00:54:56.00958",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "6043d6bb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an anomolies flag\n",
        "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
        "app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
        "\n",
        "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
        "app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n",
        "\n",
        "app_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram')\n",
        "app_test['DAYS_EMPLOYED'].plot.hist()\n",
        "plt.xlabel('Days Employment')\n",
        "\n",
        "print('There are %d anomalies in the test data out of %d entries\\n' % (app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:18.547711Z",
          "iopub.execute_input": "2024-12-15T18:26:18.547984Z",
          "iopub.status.idle": "2024-12-15T18:26:18.787827Z",
          "shell.execute_reply.started": "2024-12-15T18:26:18.547958Z",
          "shell.execute_reply": "2024-12-15T18:26:18.786977Z"
        },
        "papermill": {
          "duration": 0.284533,
          "end_time": "2024-12-01T00:54:56.841288",
          "exception": false,
          "start_time": "2024-12-01T00:54:56.556755",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "ece55f2c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# find the correlations\n",
        "correlations = app_train.corr()['TARGET'].sort_values()\n",
        "\n",
        "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
        "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:26:18.78899Z",
          "iopub.execute_input": "2024-12-15T18:26:18.789377Z",
          "iopub.status.idle": "2024-12-15T18:27:01.955497Z",
          "shell.execute_reply.started": "2024-12-15T18:26:18.789337Z",
          "shell.execute_reply": "2024-12-15T18:27:01.954536Z"
        },
        "papermill": {
          "duration": 45.221892,
          "end_time": "2024-12-01T00:55:42.072373",
          "exception": false,
          "start_time": "2024-12-01T00:54:56.850481",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "21e37297"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the correlation of the birth dates and target\n",
        "app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\n",
        "app_train['DAYS_BIRTH'].corr(app_train['TARGET'])\n",
        "\n",
        "# as clients get older, they tend to repay their loans on time"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:01.956578Z",
          "iopub.execute_input": "2024-12-15T18:27:01.95685Z",
          "iopub.status.idle": "2024-12-15T18:27:01.969906Z",
          "shell.execute_reply.started": "2024-12-15T18:27:01.956823Z",
          "shell.execute_reply": "2024-12-15T18:27:01.968978Z"
        },
        "papermill": {
          "duration": 0.027552,
          "end_time": "2024-12-01T00:55:42.108751",
          "exception": false,
          "start_time": "2024-12-01T00:55:42.081199",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "3d067607"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the style of plots\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Plot the distribution of ages in years\n",
        "plt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins = 25)\n",
        "plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:01.970975Z",
          "iopub.execute_input": "2024-12-15T18:27:01.971202Z",
          "iopub.status.idle": "2024-12-15T18:27:02.199342Z",
          "shell.execute_reply.started": "2024-12-15T18:27:01.971179Z",
          "shell.execute_reply": "2024-12-15T18:27:02.198538Z"
        },
        "papermill": {
          "duration": 0.336694,
          "end_time": "2024-12-01T00:55:42.455625",
          "exception": false,
          "start_time": "2024-12-01T00:55:42.118931",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "6b794c7f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Effect of age on target\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize = (10, 8))\n",
        "\n",
        "# KDE plot of loans that were repaid on time\n",
        "sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')\n",
        "\n",
        "# KDE plot of loans which were not repaid on time\n",
        "sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')\n",
        "\n",
        "# Labeling of plot\n",
        "plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:02.200553Z",
          "iopub.execute_input": "2024-12-15T18:27:02.200906Z",
          "iopub.status.idle": "2024-12-15T18:27:03.674853Z",
          "shell.execute_reply.started": "2024-12-15T18:27:02.200868Z",
          "shell.execute_reply": "2024-12-15T18:27:03.67394Z"
        },
        "papermill": {
          "duration": 1.607697,
          "end_time": "2024-12-01T00:55:44.073448",
          "exception": false,
          "start_time": "2024-12-01T00:55:42.465751",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "a7f922e7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Age information into a separate dataframe\n",
        "age_data = app_train[['TARGET', 'DAYS_BIRTH']]\n",
        "age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365\n",
        "\n",
        "# Bin the age data\n",
        "age_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20, 70, num = 11))\n",
        "age_data.head(10)\n",
        "\n",
        "# Group by the bin and calculate averages\n",
        "age_groups  = age_data.groupby('YEARS_BINNED').mean()\n",
        "age_groups"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:03.675886Z",
          "iopub.execute_input": "2024-12-15T18:27:03.676144Z",
          "iopub.status.idle": "2024-12-15T18:27:03.719522Z",
          "shell.execute_reply.started": "2024-12-15T18:27:03.67612Z",
          "shell.execute_reply": "2024-12-15T18:27:03.718624Z"
        },
        "papermill": {
          "duration": 0.059906,
          "end_time": "2024-12-01T00:55:44.145375",
          "exception": false,
          "start_time": "2024-12-01T00:55:44.085469",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "2a731078"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8, 8))\n",
        "\n",
        "# Graph the age bins and the average of the target as a bar plot\n",
        "plt.bar(age_groups.index.astype(str), 100 * age_groups['TARGET'])\n",
        "\n",
        "# Plot labeling\n",
        "plt.xticks(rotation = 75); plt.xlabel('Age Group (years)'); plt.ylabel('Failure to Repay (%)')\n",
        "plt.title('Failure to Repay by Age Group')\n",
        "\n",
        "# clear trend: younger applicant = highier faliur to repay loan"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:03.720681Z",
          "iopub.execute_input": "2024-12-15T18:27:03.721022Z",
          "iopub.status.idle": "2024-12-15T18:27:03.969989Z",
          "shell.execute_reply.started": "2024-12-15T18:27:03.720983Z",
          "shell.execute_reply": "2024-12-15T18:27:03.969168Z"
        },
        "papermill": {
          "duration": 0.291737,
          "end_time": "2024-12-01T00:55:44.448291",
          "exception": false,
          "start_time": "2024-12-01T00:55:44.156554",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "a43cc952"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering\n",
        "\n",
        "In this section, we will enhance the dataset by creating and transforming features to improve model performance. The following steps are performed:\n",
        "\n",
        "1. Encoding categorical variables.\n",
        "2. Creating new features based on domain knowledge.\n",
        "3. Scaling numerical features.\n",
        "\n",
        "These steps ensure the dataset is well-prepared for machine learning models and captures meaningful relationships within the data."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01206,
          "end_time": "2024-12-01T00:55:44.472514",
          "exception": false,
          "start_time": "2024-12-01T00:55:44.460454",
          "status": "completed"
        },
        "tags": [],
        "id": "d3071234"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a new dataframe for polynomial features\n",
        "poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\n",
        "poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "poly_target = poly_features['TARGET']\n",
        "poly_features = poly_features.drop(columns = ['TARGET'])\n",
        "\n",
        "poly_features = imputer.fit_transform(poly_features)\n",
        "poly_features_test = imputer.transform(poly_features_test)\n",
        "\n",
        "poly_transformer = PolynomialFeatures(degree = 3)\n",
        "\n",
        "poly_transformer.fit(poly_features)\n",
        "poly_features = poly_transformer.transform(poly_features)\n",
        "poly_features_test = poly_transformer.transform(poly_features_test)\n",
        "poly_transformer.get_feature_names_out(input_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])[:15]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:03.971232Z",
          "iopub.execute_input": "2024-12-15T18:27:03.971622Z",
          "iopub.status.idle": "2024-12-15T18:27:04.149767Z",
          "shell.execute_reply.started": "2024-12-15T18:27:03.971582Z",
          "shell.execute_reply": "2024-12-15T18:27:04.148816Z"
        },
        "papermill": {
          "duration": 0.227382,
          "end_time": "2024-12-01T00:55:44.711925",
          "exception": false,
          "start_time": "2024-12-01T00:55:44.484543",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "d77102de"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# train the polynomial features\n",
        "poly_features = pd.DataFrame(poly_features,\n",
        "                             columns = poly_transformer.get_feature_names_out(['EXT_SOURCE_1', 'EXT_SOURCE_2',\n",
        "                                                                         'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
        "poly_features['TARGET'] = poly_target\n",
        "poly_corrs = poly_features.corr()['TARGET'].sort_values()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:04.150889Z",
          "iopub.execute_input": "2024-12-15T18:27:04.151195Z",
          "iopub.status.idle": "2024-12-15T18:27:05.20473Z",
          "shell.execute_reply.started": "2024-12-15T18:27:04.151167Z",
          "shell.execute_reply": "2024-12-15T18:27:05.203848Z"
        },
        "papermill": {
          "duration": 1.107856,
          "end_time": "2024-12-01T00:55:45.832164",
          "exception": false,
          "start_time": "2024-12-01T00:55:44.724308",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "0689800e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Put test features into dataframe\n",
        "poly_features_test = pd.DataFrame(poly_features_test,\n",
        "                                  columns = poly_transformer.get_feature_names_out(['EXT_SOURCE_1', 'EXT_SOURCE_2',\n",
        "                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
        "poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']\n",
        "app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')\n",
        "\n",
        "poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\n",
        "app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\n",
        "\n",
        "# align the dfs\n",
        "app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:05.20579Z",
          "iopub.execute_input": "2024-12-15T18:27:05.206077Z",
          "iopub.status.idle": "2024-12-15T18:27:05.859989Z",
          "shell.execute_reply.started": "2024-12-15T18:27:05.206049Z",
          "shell.execute_reply": "2024-12-15T18:27:05.859267Z"
        },
        "papermill": {
          "duration": 0.72854,
          "end_time": "2024-12-01T00:55:46.574484",
          "exception": false,
          "start_time": "2024-12-01T00:55:45.845944",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "fabeec0d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "app_train_domain = app_train.copy()\n",
        "app_test_domain = app_test.copy()\n",
        "\n",
        "app_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\n",
        "app_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\n",
        "app_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\n",
        "app_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']\n",
        "\n",
        "app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\n",
        "app_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\n",
        "app_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\n",
        "app_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']\n",
        "\n",
        "plt.figure(figsize = (12, 20))\n",
        "for i, feature in enumerate(['CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT']):\n",
        "    plt.subplot(4, 1, i + 1)\n",
        "    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 0, feature], label = 'target == 0')\n",
        "    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 1, feature], label = 'target == 1')\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.title('Distribution of %s by Target Value' % feature)\n",
        "    plt.xlabel('%s' % feature); plt.ylabel('Density');\n",
        "\n",
        "plt.tight_layout(h_pad = 2.5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:05.863847Z",
          "iopub.execute_input": "2024-12-15T18:27:05.864128Z",
          "iopub.status.idle": "2024-12-15T18:27:12.229994Z",
          "shell.execute_reply.started": "2024-12-15T18:27:05.864101Z",
          "shell.execute_reply": "2024-12-15T18:27:12.229158Z"
        },
        "papermill": {
          "duration": 6.862591,
          "end_time": "2024-12-01T00:55:53.451483",
          "exception": false,
          "start_time": "2024-12-01T00:55:46.588892",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "563d540a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_apps_processed(apps):\n",
        "    \"\"\"\n",
        "    feature engineering for apps\n",
        "    \"\"\"\n",
        "\n",
        "    # 1.EXT_SOURCE\n",
        "    apps['APPS_EXT_SOURCE_MEAN'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
        "    apps['APPS_EXT_SOURCE_STD'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
        "    apps['APPS_EXT_SOURCE_STD'] = apps['APPS_EXT_SOURCE_STD'].fillna(apps['APPS_EXT_SOURCE_STD'].mean())\n",
        "\n",
        "    # AMT_CREDIT\n",
        "    apps['APPS_ANNUITY_CREDIT_RATIO'] = apps['AMT_ANNUITY']/apps['AMT_CREDIT']\n",
        "    apps['APPS_GOODS_CREDIT_RATIO'] = apps['AMT_GOODS_PRICE']/apps['AMT_CREDIT']\n",
        "\n",
        "    # AMT_INCOME_TOTAL\n",
        "    apps['APPS_ANNUITY_INCOME_RATIO'] = apps['AMT_ANNUITY']/apps['AMT_INCOME_TOTAL']\n",
        "    apps['APPS_CREDIT_INCOME_RATIO'] = apps['AMT_CREDIT']/apps['AMT_INCOME_TOTAL']\n",
        "    apps['APPS_GOODS_INCOME_RATIO'] = apps['AMT_GOODS_PRICE']/apps['AMT_INCOME_TOTAL']\n",
        "    apps['APPS_CNT_FAM_INCOME_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['CNT_FAM_MEMBERS']\n",
        "\n",
        "    # DAYS_BIRTH, DAYS_EMPLOYED\n",
        "    apps['APPS_EMPLOYED_BIRTH_RATIO'] = apps['DAYS_EMPLOYED']/apps['DAYS_BIRTH']\n",
        "    apps['APPS_INCOME_EMPLOYED_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['DAYS_EMPLOYED']\n",
        "    apps['APPS_INCOME_BIRTH_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['DAYS_BIRTH']\n",
        "    apps['APPS_CAR_BIRTH_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_BIRTH']\n",
        "    apps['APPS_CAR_EMPLOYED_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_EMPLOYED']\n",
        "\n",
        "    return apps"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:12.231567Z",
          "iopub.execute_input": "2024-12-15T18:27:12.231961Z",
          "iopub.status.idle": "2024-12-15T18:27:12.242024Z",
          "shell.execute_reply.started": "2024-12-15T18:27:12.231909Z",
          "shell.execute_reply": "2024-12-15T18:27:12.241051Z"
        },
        "papermill": {
          "duration": 0.030663,
          "end_time": "2024-12-01T00:55:53.500532",
          "exception": false,
          "start_time": "2024-12-01T00:55:53.469869",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "3e819859"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prev_processed(prev):\n",
        "    \"\"\"\n",
        "    feature engineering\n",
        "    for previous application credit history\n",
        "    \"\"\"\n",
        "    prev['PREV_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
        "    prev['PREV_GOODS_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_GOODS_PRICE']\n",
        "    prev['PREV_CREDIT_APPL_RATIO'] = prev['AMT_CREDIT']/prev['AMT_APPLICATION']\n",
        "    prev['PREV_GOODS_APPL_RATIO'] = prev['AMT_GOODS_PRICE']/prev['AMT_APPLICATION']\n",
        "\n",
        "    prev['DAYS_FIRST_DRAWING'] = prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan)\n",
        "    prev['DAYS_FIRST_DUE'] = prev['DAYS_FIRST_DUE'].replace(365243, np.nan)\n",
        "    prev['DAYS_LAST_DUE_1ST_VERSION'] = prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan)\n",
        "    prev['DAYS_LAST_DUE'] = prev['DAYS_LAST_DUE'].replace(365243, np.nan)\n",
        "    prev['DAYS_TERMINATION'] = prev['DAYS_TERMINATION'].replace(365243, np.nan)\n",
        "\n",
        "    prev['PREV_DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
        "\n",
        "    all_pay = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
        "    prev['PREV_INTERESTS_RATE'] = (all_pay/prev['AMT_CREDIT'] - 1)/prev['CNT_PAYMENT']\n",
        "\n",
        "    return prev\n",
        "\n",
        "def get_prev_amt_agg(prev):\n",
        "    \"\"\"\n",
        "    feature enginnering for the previous credit application\n",
        "    \"\"\"\n",
        "    agg_dict = {\n",
        "      'SK_ID_CURR':['count'],\n",
        "      'AMT_CREDIT':['mean', 'max', 'sum'],\n",
        "      'AMT_ANNUITY':['mean', 'max', 'sum'],\n",
        "      'AMT_APPLICATION':['mean', 'max', 'sum'],\n",
        "      'AMT_DOWN_PAYMENT':['mean', 'max', 'sum'],\n",
        "      'AMT_GOODS_PRICE':['mean', 'max', 'sum'],\n",
        "      'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
        "      'DAYS_DECISION': ['min', 'max', 'mean'],\n",
        "      'CNT_PAYMENT': ['mean', 'sum'],\n",
        "\n",
        "      'PREV_CREDIT_DIFF':['mean', 'max', 'sum'],\n",
        "      'PREV_CREDIT_APPL_RATIO':['mean', 'max'],\n",
        "      'PREV_GOODS_DIFF':['mean', 'max', 'sum'],\n",
        "      'PREV_GOODS_APPL_RATIO':['mean', 'max'],\n",
        "      'PREV_DAYS_LAST_DUE_DIFF':['mean', 'max', 'sum'],\n",
        "      'PREV_INTERESTS_RATE':['mean', 'max']\n",
        "    }\n",
        "\n",
        "    prev_group = prev.groupby('SK_ID_CURR')\n",
        "    prev_amt_agg = prev_group.agg(agg_dict)\n",
        "    prev_amt_agg.columns = [\"PREV_\"+ \"_\".join(x).upper() for x in prev_amt_agg.columns.ravel()]\n",
        "\n",
        "    return prev_amt_agg\n",
        "\n",
        "def get_prev_refused_appr_agg(prev):\n",
        "    \"\"\"\n",
        "    PREV_APPROVED_COUNT : Credit application approved count\n",
        "    PREV_REFUSED_COUNT :  Credit application refused count\n",
        "    \"\"\"\n",
        "    prev_refused_appr_group = prev[prev['NAME_CONTRACT_STATUS'].isin(['Approved', 'Refused'])].groupby([ 'SK_ID_CURR', 'NAME_CONTRACT_STATUS'])\n",
        "    prev_refused_appr_agg = prev_refused_appr_group['SK_ID_CURR'].count().unstack()\n",
        "    prev_refused_appr_agg.columns = ['PREV_APPROVED_COUNT', 'PREV_REFUSED_COUNT' ]\n",
        "    prev_refused_appr_agg = prev_refused_appr_agg.fillna(0)\n",
        "    return prev_refused_appr_agg\n",
        "\n",
        "\n",
        "def get_prev_days365_agg(prev):\n",
        "    \"\"\"\n",
        "    DAYS_DESCISION means How many days have been take since the previous credit application made.\n",
        "    Somehow this feature is important.\n",
        "    \"\"\"\n",
        "    cond_days365 = prev['DAYS_DECISION'] > -365\n",
        "    prev_days365_group = prev[cond_days365].groupby('SK_ID_CURR')\n",
        "    agg_dict = {\n",
        "      'SK_ID_CURR':['count'],\n",
        "      'AMT_CREDIT':['mean', 'max', 'sum'],\n",
        "      'AMT_ANNUITY':['mean', 'max', 'sum'],\n",
        "      'AMT_APPLICATION':['mean', 'max', 'sum'],\n",
        "      'AMT_DOWN_PAYMENT':['mean', 'max', 'sum'],\n",
        "      'AMT_GOODS_PRICE':['mean', 'max', 'sum'],\n",
        "      'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
        "      'DAYS_DECISION': ['min', 'max', 'mean'],\n",
        "      'CNT_PAYMENT': ['mean', 'sum'],\n",
        "\n",
        "      'PREV_CREDIT_DIFF':['mean', 'max', 'sum'],\n",
        "      'PREV_CREDIT_APPL_RATIO':['mean', 'max'],\n",
        "      'PREV_GOODS_DIFF':['mean', 'max', 'sum'],\n",
        "      'PREV_GOODS_APPL_RATIO':['mean', 'max'],\n",
        "      'PREV_DAYS_LAST_DUE_DIFF':['mean', 'max', 'sum'],\n",
        "      'PREV_INTERESTS_RATE':['mean', 'max']\n",
        "    }\n",
        "\n",
        "    prev_days365_agg = prev_days365_group.agg(agg_dict)\n",
        "\n",
        "    # multi index\n",
        "    prev_days365_agg.columns = [\"PREV_D365_\"+ \"_\".join(x).upper() for x in prev_days365_agg.columns.ravel()]\n",
        "\n",
        "    return prev_days365_agg\n",
        "\n",
        "def get_prev_agg(prev):\n",
        "    prev = get_prev_processed(prev)\n",
        "    prev_amt_agg = get_prev_amt_agg(prev)\n",
        "    prev_refused_appr_agg = get_prev_refused_appr_agg(prev)\n",
        "    prev_days365_agg = get_prev_days365_agg(prev)\n",
        "\n",
        "    # prev_amt_agg\n",
        "    prev_agg = prev_amt_agg.merge(prev_refused_appr_agg, on='SK_ID_CURR', how='left')\n",
        "    prev_agg = prev_agg.merge(prev_days365_agg, on='SK_ID_CURR', how='left')\n",
        "    # SK_ID_CURR APPROVED_COUNT REFUSED_COUNT\n",
        "    prev_agg['PREV_REFUSED_RATIO'] = prev_agg['PREV_REFUSED_COUNT']/prev_agg['PREV_SK_ID_CURR_COUNT']\n",
        "    prev_agg['PREV_APPROVED_RATIO'] = prev_agg['PREV_APPROVED_COUNT']/prev_agg['PREV_SK_ID_CURR_COUNT']\n",
        "    # 'PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT' drop\n",
        "    prev_agg = prev_agg.drop(['PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT'], axis=1)\n",
        "\n",
        "    return prev_agg"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:12.243312Z",
          "iopub.execute_input": "2024-12-15T18:27:12.243687Z",
          "iopub.status.idle": "2024-12-15T18:27:12.264678Z",
          "shell.execute_reply.started": "2024-12-15T18:27:12.243661Z",
          "shell.execute_reply": "2024-12-15T18:27:12.26385Z"
        },
        "papermill": {
          "duration": 0.034742,
          "end_time": "2024-12-01T00:55:53.552258",
          "exception": false,
          "start_time": "2024-12-01T00:55:53.517516",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "08bf776a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bureau_processed(bureau):\n",
        "    bureau['BUREAU_ENDDATE_FACT_DIFF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
        "    bureau['BUREAU_CREDIT_FACT_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_ENDDATE_FACT']\n",
        "    bureau['BUREAU_CREDIT_ENDDATE_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_CREDIT_ENDDATE']\n",
        "    bureau['BUREAU_CREDIT_DEBT_RATIO']=bureau['AMT_CREDIT_SUM_DEBT']/bureau['AMT_CREDIT_SUM']\n",
        "    bureau['BUREAU_CREDIT_DEBT_DIFF'] = bureau['AMT_CREDIT_SUM_DEBT'] - bureau['AMT_CREDIT_SUM']\n",
        "\n",
        "    bureau['BUREAU_IS_DPD'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 0 else 0)\n",
        "    bureau['BUREAU_IS_DPD_OVER120'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x >120 else 0)\n",
        "\n",
        "    return bureau\n",
        "\n",
        "def get_bureau_day_amt_agg(bureau):\n",
        "    bureau_agg_dict = {\n",
        "    'SK_ID_BUREAU':['count'],\n",
        "    'DAYS_CREDIT':['min', 'max', 'mean'],\n",
        "    'CREDIT_DAY_OVERDUE':['min', 'max', 'mean'],\n",
        "    'DAYS_CREDIT_ENDDATE':['min', 'max', 'mean'],\n",
        "    'DAYS_ENDDATE_FACT':['min', 'max', 'mean'],\n",
        "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
        "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
        "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
        "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n",
        "    'AMT_ANNUITY': ['max', 'mean', 'sum'],\n",
        "\n",
        "    'BUREAU_ENDDATE_FACT_DIFF':['min', 'max', 'mean'],\n",
        "    'BUREAU_CREDIT_FACT_DIFF':['min', 'max', 'mean'],\n",
        "    'BUREAU_CREDIT_ENDDATE_DIFF':['min', 'max', 'mean'],\n",
        "    'BUREAU_CREDIT_DEBT_RATIO':['min', 'max', 'mean'],\n",
        "    'BUREAU_CREDIT_DEBT_DIFF':['min', 'max', 'mean'],\n",
        "    'BUREAU_IS_DPD':['mean', 'sum'],\n",
        "    'BUREAU_IS_DPD_OVER120':['mean', 'sum']\n",
        "    }\n",
        "\n",
        "    bureau_grp = bureau.groupby('SK_ID_CURR')\n",
        "    bureau_day_amt_agg = bureau_grp.agg(bureau_agg_dict)\n",
        "    bureau_day_amt_agg.columns = ['BUREAU_'+('_').join(column).upper() for column in bureau_day_amt_agg.columns.ravel()]\n",
        "    # SK_ID_CURR reset_index()\n",
        "    bureau_day_amt_agg = bureau_day_amt_agg.reset_index()\n",
        "    #print('bureau_day_amt_agg shape:', bureau_day_amt_agg.shape)\n",
        "    return bureau_day_amt_agg\n",
        "\n",
        "def get_bureau_active_agg(bureau):\n",
        "    cond_active = bureau['CREDIT_ACTIVE'] == 'Active'\n",
        "    bureau_active_grp = bureau[cond_active].groupby(['SK_ID_CURR'])\n",
        "    bureau_agg_dict = {\n",
        "      'SK_ID_BUREAU':['count'],\n",
        "      'DAYS_CREDIT':['min', 'max', 'mean'],\n",
        "      'CREDIT_DAY_OVERDUE':['min', 'max', 'mean'],\n",
        "      'DAYS_CREDIT_ENDDATE':['min', 'max', 'mean'],\n",
        "      'DAYS_ENDDATE_FACT':['min', 'max', 'mean'],\n",
        "      'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
        "      'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
        "      'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
        "      'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n",
        "      'AMT_ANNUITY': ['max', 'mean', 'sum'],\n",
        "\n",
        "      'BUREAU_ENDDATE_FACT_DIFF':['min', 'max', 'mean'],\n",
        "      'BUREAU_CREDIT_FACT_DIFF':['min', 'max', 'mean'],\n",
        "      'BUREAU_CREDIT_ENDDATE_DIFF':['min', 'max', 'mean'],\n",
        "      'BUREAU_CREDIT_DEBT_RATIO':['min', 'max', 'mean'],\n",
        "      'BUREAU_CREDIT_DEBT_DIFF':['min', 'max', 'mean'],\n",
        "      'BUREAU_IS_DPD':['mean', 'sum'],\n",
        "      'BUREAU_IS_DPD_OVER120':['mean', 'sum']\n",
        "      }\n",
        "\n",
        "    bureau_active_agg = bureau_active_grp.agg(bureau_agg_dict)\n",
        "    bureau_active_agg.columns = ['BUREAU_ACT_'+('_').join(column).upper() for column in bureau_active_agg.columns.ravel()]\n",
        "    bureau_active_agg = bureau_active_agg.reset_index()\n",
        "\n",
        "    return bureau_active_agg\n",
        "\n",
        "\n",
        "def get_bureau_bal_agg(bureau, bureau_bal):\n",
        "    bureau_bal = bureau_bal.merge(bureau[['SK_ID_CURR', 'SK_ID_BUREAU']], on='SK_ID_BUREAU', how='left')\n",
        "    bureau_bal['BUREAU_BAL_IS_DPD'] = bureau_bal['STATUS'].apply(lambda x: 1 if x in['1','2','3','4','5']  else 0)\n",
        "    bureau_bal['BUREAU_BAL_IS_DPD_OVER120'] = bureau_bal['STATUS'].apply(lambda x: 1 if x =='5'  else 0)\n",
        "    bureau_bal_grp = bureau_bal.groupby('SK_ID_CURR')\n",
        "\n",
        "    bureau_bal_agg_dict = {\n",
        "        'SK_ID_CURR':['count'],\n",
        "        'MONTHS_BALANCE':['min', 'max', 'mean'],\n",
        "        'BUREAU_BAL_IS_DPD':['mean', 'sum'],\n",
        "        'BUREAU_BAL_IS_DPD_OVER120':['mean', 'sum']\n",
        "    }\n",
        "\n",
        "    bureau_bal_agg = bureau_bal_grp.agg(bureau_bal_agg_dict)\n",
        "    bureau_bal_agg.columns = [ 'BUREAU_BAL_'+('_').join(column).upper() for column in bureau_bal_agg.columns.ravel() ]\n",
        "\n",
        "    bureau_bal_agg = bureau_bal_agg.reset_index()\n",
        "    return bureau_bal_agg\n",
        "\n",
        "def get_bureau_agg(bureau, bureau_bal):\n",
        "    bureau = get_bureau_processed(bureau)\n",
        "    bureau_day_amt_agg = get_bureau_day_amt_agg(bureau)\n",
        "    bureau_active_agg = get_bureau_active_agg(bureau)\n",
        "    bureau_bal_agg = get_bureau_bal_agg(bureau, bureau_bal)\n",
        "\n",
        "    bureau_agg = bureau_day_amt_agg.merge(bureau_active_agg, on='SK_ID_CURR', how='left')\n",
        "    bureau_agg['BUREAU_ACT_IS_DPD_RATIO'] = bureau_agg['BUREAU_ACT_BUREAU_IS_DPD_SUM']/bureau_agg['BUREAU_SK_ID_BUREAU_COUNT']\n",
        "    bureau_agg['BUREAU_ACT_IS_DPD_OVER120_RATIO'] = bureau_agg['BUREAU_ACT_BUREAU_IS_DPD_OVER120_SUM']/bureau_agg['BUREAU_SK_ID_BUREAU_COUNT']\n",
        "\n",
        "    bureau_agg = bureau_agg.merge(bureau_bal_agg, on='SK_ID_CURR', how='left')\n",
        "    #bureau_agg = bureau_agg.merge(bureau_days750_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    return bureau_agg"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:12.26593Z",
          "iopub.execute_input": "2024-12-15T18:27:12.266226Z",
          "iopub.status.idle": "2024-12-15T18:27:12.283434Z",
          "shell.execute_reply.started": "2024-12-15T18:27:12.266198Z",
          "shell.execute_reply": "2024-12-15T18:27:12.282732Z"
        },
        "papermill": {
          "duration": 0.035799,
          "end_time": "2024-12-01T00:55:53.605092",
          "exception": false,
          "start_time": "2024-12-01T00:55:53.569293",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "5638ce78"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos_bal_agg(pos_bal):\n",
        "    cond_over_0 = pos_bal['SK_DPD'] > 0\n",
        "    cond_100 = (pos_bal['SK_DPD'] < 100) & (pos_bal['SK_DPD'] > 0)\n",
        "    cond_over_100 = (pos_bal['SK_DPD'] >= 100)\n",
        "\n",
        "    pos_bal['POS_IS_DPD'] = pos_bal['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
        "    pos_bal['POS_IS_DPD_UNDER_120'] = pos_bal['SK_DPD'].apply(lambda x:1 if (x > 0) & (x <120) else 0 )\n",
        "    pos_bal['POS_IS_DPD_OVER_120'] = pos_bal['SK_DPD'].apply(lambda x:1 if x >= 120 else 0)\n",
        "\n",
        "    pos_bal_grp = pos_bal.groupby('SK_ID_CURR')\n",
        "    pos_bal_agg_dict = {\n",
        "        'SK_ID_CURR':['count'],\n",
        "        'MONTHS_BALANCE':['min', 'mean', 'max'],\n",
        "        'SK_DPD':['min', 'max', 'mean', 'sum'],\n",
        "        'CNT_INSTALMENT':['min', 'max', 'mean', 'sum'],\n",
        "        'CNT_INSTALMENT_FUTURE':['min', 'max', 'mean', 'sum'],\n",
        "\n",
        "        'POS_IS_DPD':['mean', 'sum'],\n",
        "        'POS_IS_DPD_UNDER_120':['mean', 'sum'],\n",
        "        'POS_IS_DPD_OVER_120':['mean', 'sum']\n",
        "    }\n",
        "\n",
        "    pos_bal_agg = pos_bal_grp.agg(pos_bal_agg_dict)\n",
        "\n",
        "    pos_bal_agg.columns = [('POS_')+('_').join(column).upper() for column in pos_bal_agg.columns.ravel()]\n",
        "\n",
        "    cond_months = pos_bal['MONTHS_BALANCE'] > -20\n",
        "    pos_bal_m20_grp = pos_bal[cond_months].groupby('SK_ID_CURR')\n",
        "    pos_bal_m20_agg_dict = {\n",
        "        'SK_ID_CURR':['count'],\n",
        "        'MONTHS_BALANCE':['min', 'mean', 'max'],\n",
        "        'SK_DPD':['min', 'max', 'mean', 'sum'],\n",
        "        'CNT_INSTALMENT':['min', 'max', 'mean', 'sum'],\n",
        "        'CNT_INSTALMENT_FUTURE':['min', 'max', 'mean', 'sum'],\n",
        "\n",
        "        'POS_IS_DPD':['mean', 'sum'],\n",
        "        'POS_IS_DPD_UNDER_120':['mean', 'sum'],\n",
        "        'POS_IS_DPD_OVER_120':['mean', 'sum']\n",
        "    }\n",
        "\n",
        "    pos_bal_m20_agg = pos_bal_m20_grp.agg(pos_bal_m20_agg_dict)\n",
        "\n",
        "    pos_bal_m20_agg.columns = [('POS_M20')+('_').join(column).upper() for column in pos_bal_m20_agg.columns.ravel()]\n",
        "    pos_bal_agg = pos_bal_agg.merge(pos_bal_m20_agg, on='SK_ID_CURR', how='left')\n",
        "    pos_bal_agg = pos_bal_agg.reset_index()\n",
        "\n",
        "\n",
        "    return pos_bal_agg"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:12.284747Z",
          "iopub.execute_input": "2024-12-15T18:27:12.285038Z",
          "iopub.status.idle": "2024-12-15T18:27:12.298048Z",
          "shell.execute_reply.started": "2024-12-15T18:27:12.284997Z",
          "shell.execute_reply": "2024-12-15T18:27:12.297301Z"
        },
        "papermill": {
          "duration": 0.030047,
          "end_time": "2024-12-01T00:55:53.652222",
          "exception": false,
          "start_time": "2024-12-01T00:55:53.622175",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "9b0e1adc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_install_agg(install):\n",
        "    install['AMT_DIFF'] = install['AMT_INSTALMENT'] - install['AMT_PAYMENT']\n",
        "    install['AMT_RATIO'] =  (install['AMT_PAYMENT'] +1)/ (install['AMT_INSTALMENT'] + 1)\n",
        "    install['SK_DPD'] = install['DAYS_ENTRY_PAYMENT'] - install['DAYS_INSTALMENT']\n",
        "\n",
        "    install['INS_IS_DPD'] = install['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
        "    install['INS_IS_DPD_UNDER_120'] = install['SK_DPD'].apply(lambda x:1 if (x > 0) & (x <120) else 0 )\n",
        "    install['INS_IS_DPD_OVER_120'] = install['SK_DPD'].apply(lambda x:1 if x >= 120 else 0)\n",
        "\n",
        "    install_grp = install.groupby('SK_ID_CURR')\n",
        "\n",
        "    install_agg_dict = {\n",
        "        'SK_ID_CURR':['count'],\n",
        "        'NUM_INSTALMENT_VERSION':['nunique'],\n",
        "        'DAYS_ENTRY_PAYMENT':['mean', 'max', 'sum'],\n",
        "        'DAYS_INSTALMENT':['mean', 'max', 'sum'],\n",
        "        'AMT_INSTALMENT':['mean', 'max', 'sum'],\n",
        "        'AMT_PAYMENT':['mean', 'max','sum'],\n",
        "\n",
        "        'AMT_DIFF':['mean','min', 'max','sum'],\n",
        "        'AMT_RATIO':['mean', 'max'],\n",
        "        'SK_DPD':['mean', 'min', 'max'],\n",
        "        'INS_IS_DPD':['mean', 'sum'],\n",
        "        'INS_IS_DPD_UNDER_120':['mean', 'sum'],\n",
        "        'INS_IS_DPD_OVER_120':['mean', 'sum']\n",
        "    }\n",
        "\n",
        "    install_agg = install_grp.agg(install_agg_dict)\n",
        "    install_agg.columns = ['INS_'+('_').join(column).upper() for column in install_agg.columns.ravel()]\n",
        "\n",
        "    cond_day = install['DAYS_ENTRY_PAYMENT'] >= -365\n",
        "    install_d365_grp = install[cond_day].groupby('SK_ID_CURR')\n",
        "    install_d365_agg_dict = {\n",
        "        'SK_ID_CURR':['count'],\n",
        "        'NUM_INSTALMENT_VERSION':['nunique'],\n",
        "        'DAYS_ENTRY_PAYMENT':['mean', 'max', 'sum'],\n",
        "        'DAYS_INSTALMENT':['mean', 'max', 'sum'],\n",
        "        'AMT_INSTALMENT':['mean', 'max', 'sum'],\n",
        "        'AMT_PAYMENT':['mean', 'max','sum'],\n",
        "\n",
        "        'AMT_DIFF':['mean','min', 'max','sum'],\n",
        "        'AMT_RATIO':['mean', 'max'],\n",
        "        'SK_DPD':['mean', 'min', 'max'],\n",
        "        'INS_IS_DPD':['mean', 'sum'],\n",
        "        'INS_IS_DPD_UNDER_120':['mean', 'sum'],\n",
        "        'INS_IS_DPD_OVER_120':['mean', 'sum']\n",
        "    }\n",
        "\n",
        "    install_d365_agg = install_d365_grp.agg(install_d365_agg_dict)\n",
        "    install_d365_agg.columns = ['INS_D365'+('_').join(column).upper() for column in install_d365_agg.columns.ravel()]\n",
        "\n",
        "    install_agg = install_agg.merge(install_d365_agg, on='SK_ID_CURR', how='left')\n",
        "    install_agg = install_agg.reset_index()\n",
        "\n",
        "    return install_agg"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:12.299104Z",
          "iopub.execute_input": "2024-12-15T18:27:12.299381Z",
          "iopub.status.idle": "2024-12-15T18:27:12.31292Z",
          "shell.execute_reply.started": "2024-12-15T18:27:12.299357Z",
          "shell.execute_reply": "2024-12-15T18:27:12.312073Z"
        },
        "papermill": {
          "duration": 0.031247,
          "end_time": "2024-12-01T00:55:53.701522",
          "exception": false,
          "start_time": "2024-12-01T00:55:53.670275",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "f39c8c07"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_card_bal_agg(card_bal):\n",
        "    card_bal['BALANCE_LIMIT_RATIO'] = card_bal['AMT_BALANCE']/card_bal['AMT_CREDIT_LIMIT_ACTUAL']\n",
        "    card_bal['DRAWING_LIMIT_RATIO'] = card_bal['AMT_DRAWINGS_CURRENT'] / card_bal['AMT_CREDIT_LIMIT_ACTUAL']\n",
        "\n",
        "    card_bal['CARD_IS_DPD'] = card_bal['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
        "    card_bal['CARD_IS_DPD_UNDER_120'] = card_bal['SK_DPD'].apply(lambda x:1 if (x > 0) & (x <120) else 0 )\n",
        "    card_bal['CARD_IS_DPD_OVER_120'] = card_bal['SK_DPD'].apply(lambda x:1 if x >= 120 else 0)\n",
        "\n",
        "    card_bal_grp = card_bal.groupby('SK_ID_CURR')\n",
        "    card_bal_agg_dict = {\n",
        "        'SK_ID_CURR':['count'],\n",
        "        'AMT_BALANCE':['max'],\n",
        "        'AMT_CREDIT_LIMIT_ACTUAL':['max'],\n",
        "        'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n",
        "        'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n",
        "        'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n",
        "        'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n",
        "        'AMT_PAYMENT_TOTAL_CURRENT': ['max','sum'],\n",
        "        'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n",
        "        'CNT_DRAWINGS_ATM_CURRENT': ['max','sum'],\n",
        "        'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n",
        "        'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n",
        "        'SK_DPD': ['mean', 'max', 'sum'],\n",
        "\n",
        "        'BALANCE_LIMIT_RATIO':['min','max'],\n",
        "        'DRAWING_LIMIT_RATIO':['min', 'max'],\n",
        "        'CARD_IS_DPD':['mean', 'sum'],\n",
        "        'CARD_IS_DPD_UNDER_120':['mean', 'sum'],\n",
        "        'CARD_IS_DPD_OVER_120':['mean', 'sum']\n",
        "    }\n",
        "    card_bal_agg = card_bal_grp.agg(card_bal_agg_dict)\n",
        "    card_bal_agg.columns = ['CARD_'+('_').join(column).upper() for column in card_bal_agg.columns.ravel()]\n",
        "\n",
        "    card_bal_agg = card_bal_agg.reset_index()\n",
        "\n",
        "    cond_month = card_bal.MONTHS_BALANCE >= -3\n",
        "    card_bal_m3_grp = card_bal[cond_month].groupby('SK_ID_CURR')\n",
        "    card_bal_m3_agg = card_bal_m3_grp.agg(card_bal_agg_dict)\n",
        "    card_bal_m3_agg.columns = ['CARD_M3'+('_').join(column).upper() for column in card_bal_m3_agg.columns.ravel()]\n",
        "\n",
        "    card_bal_agg = card_bal_agg.merge(card_bal_m3_agg, on='SK_ID_CURR', how='left')\n",
        "    card_bal_agg = card_bal_agg.reset_index()\n",
        "\n",
        "    return card_bal_agg"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:12.314012Z",
          "iopub.execute_input": "2024-12-15T18:27:12.314256Z",
          "iopub.status.idle": "2024-12-15T18:27:12.329089Z",
          "shell.execute_reply.started": "2024-12-15T18:27:12.314231Z",
          "shell.execute_reply": "2024-12-15T18:27:12.328336Z"
        },
        "papermill": {
          "duration": 0.029892,
          "end_time": "2024-12-01T00:55:53.749016",
          "exception": false,
          "start_time": "2024-12-01T00:55:53.719124",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "d4f01f8f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# scale each feature to 0-1\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "\n",
        "\n",
        "if 'TARGET' in app_train:\n",
        "    train = app_train.drop(columns = ['TARGET'])\n",
        "else:\n",
        "    train = app_train.copy()\n",
        "\n",
        "test = app_test.copy()\n",
        "features = list(train.columns)\n",
        "\n",
        "imputer.fit(train)\n",
        "train = imputer.transform(train)\n",
        "test = imputer.transform(app_test)\n",
        "\n",
        "scaler.fit(train)\n",
        "train = scaler.transform(train)\n",
        "test = scaler.transform(test)\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n",
        "\n",
        "random_forest.fit(train, train_labels)\n",
        "\n",
        "feature_importance_values = random_forest.feature_importances_\n",
        "feature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\n",
        "\n",
        "predictions = random_forest.predict_proba(test)[:, 1]\n",
        "\n",
        "submit = app_test[['SK_ID_CURR']]\n",
        "submit['TARGET'] = predictions\n",
        "\n",
        "app_train_domain = app_train_domain.drop(columns = 'TARGET')\n",
        "\n",
        "domain_features_names = list(app_train_domain.columns)\n",
        "\n",
        "domain_features = imputer.fit_transform(app_train_domain)\n",
        "domain_features_test = imputer.transform(app_test_domain)\n",
        "\n",
        "domain_features = scaler.fit_transform(domain_features)\n",
        "domain_features_test = scaler.transform(domain_features_test)\n",
        "\n",
        "random_forest_domain = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n",
        "\n",
        "random_forest_domain.fit(domain_features, train_labels)\n",
        "\n",
        "feature_importance_values_domain = random_forest_domain.feature_importances_\n",
        "feature_importances_domain = pd.DataFrame({'feature': domain_features_names, 'importance': feature_importance_values_domain})\n",
        "\n",
        "predictions = random_forest_domain.predict_proba(domain_features_test)[:, 1]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:27:12.330037Z",
          "iopub.execute_input": "2024-12-15T18:27:12.330296Z",
          "iopub.status.idle": "2024-12-15T18:29:35.883528Z",
          "shell.execute_reply.started": "2024-12-15T18:27:12.330253Z",
          "shell.execute_reply": "2024-12-15T18:29:35.882523Z"
        },
        "papermill": {
          "duration": 161.352466,
          "end_time": "2024-12-01T00:58:35.118516",
          "exception": false,
          "start_time": "2024-12-01T00:55:53.76605",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "a04d3bf2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset():\n",
        "    app_train = pd.read_csv(os.path.join(default_dir,'application_train.csv'))\n",
        "    app_test = pd.read_csv(os.path.join(default_dir,'application_test.csv'))\n",
        "    apps = pd.concat([app_train, app_test])\n",
        "\n",
        "    prev = pd.read_csv(os.path.join(default_dir,'previous_application.csv'))\n",
        "    bureau = pd.read_csv(os.path.join(default_dir,'bureau.csv'))\n",
        "    bureau_bal = pd.read_csv(os.path.join(default_dir,'bureau_balance.csv'))\n",
        "\n",
        "    pos_bal, install, card_bal = get_balance_data()\n",
        "\n",
        "    return apps, prev, bureau, bureau_bal, pos_bal, install, card_bal\n",
        "\n",
        "apps, prev, bureau, bureau_bal, pos_bal, install, card_bal = get_dataset()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:29:35.884912Z",
          "iopub.execute_input": "2024-12-15T18:29:35.88519Z",
          "iopub.status.idle": "2024-12-15T18:30:33.62487Z",
          "shell.execute_reply.started": "2024-12-15T18:29:35.885163Z",
          "shell.execute_reply": "2024-12-15T18:30:33.624137Z"
        },
        "papermill": {
          "duration": 60.128559,
          "end_time": "2024-12-01T00:59:35.265371",
          "exception": false,
          "start_time": "2024-12-01T00:58:35.136812",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "a1025a13"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_apps_all_with_all_agg(apps, prev, bureau, bureau_bal, pos_bal, install, card_bal):\n",
        "    \"\"\"\n",
        "    Description :\n",
        "    1.Data preparation , aggregation\n",
        "    2.produce the finalized result\n",
        "    \"\"\"\n",
        "    apps_all =  get_apps_processed(apps)\n",
        "    prev_agg = get_prev_agg(prev)\n",
        "    bureau_agg = get_bureau_agg(bureau, bureau_bal)\n",
        "    pos_bal_agg = get_pos_bal_agg(pos_bal)\n",
        "    install_agg = get_install_agg(install)\n",
        "    card_bal_agg = get_card_bal_agg(card_bal)\n",
        "    print('prev_agg shape:', prev_agg.shape, 'bureau_agg shape:', bureau_agg.shape )\n",
        "    print('pos_bal_agg shape:', pos_bal_agg.shape, 'install_agg shape:', install_agg.shape, 'card_bal_agg shape:', card_bal_agg.shape)\n",
        "    print('apps_all before merge shape:', apps_all.shape)\n",
        "\n",
        "    # Join with apps_all\n",
        "    apps_all = apps_all.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
        "    apps_all = apps_all.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
        "    apps_all = apps_all.merge(pos_bal_agg, on='SK_ID_CURR', how='left')\n",
        "    apps_all = apps_all.merge(install_agg, on='SK_ID_CURR', how='left')\n",
        "    apps_all = apps_all.merge(card_bal_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    print('apps_all after merge with all shape:', apps_all.shape)\n",
        "\n",
        "    return apps_all"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:30:33.626157Z",
          "iopub.execute_input": "2024-12-15T18:30:33.626804Z",
          "iopub.status.idle": "2024-12-15T18:30:33.633426Z",
          "shell.execute_reply.started": "2024-12-15T18:30:33.626762Z",
          "shell.execute_reply": "2024-12-15T18:30:33.632628Z"
        },
        "papermill": {
          "duration": 0.027461,
          "end_time": "2024-12-01T00:59:35.311459",
          "exception": false,
          "start_time": "2024-12-01T00:59:35.283998",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "d8f2cad9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_apps_all_with_prev_agg(apps, prev):\n",
        "    apps_all =  get_apps_processed(apps)\n",
        "    prev_agg = get_prev_agg(prev)\n",
        "    print('prev_agg shape:', prev_agg.shape)\n",
        "    print('apps_all before merge shape:', apps_all.shape)\n",
        "    apps_all = apps_all.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
        "    print('apps_all after merge with prev_agg shape:', apps_all.shape)\n",
        "\n",
        "    return apps_all\n",
        "\n",
        "def get_apps_all_encoded(apps_all):\n",
        "    object_columns = apps_all.dtypes[apps_all.dtypes == 'object'].index.tolist()\n",
        "    for column in object_columns:\n",
        "        apps_all[column] = pd.factorize(apps_all[column])[0]\n",
        "\n",
        "    return apps_all"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-15T18:30:33.63443Z",
          "iopub.execute_input": "2024-12-15T18:30:33.634685Z",
          "iopub.status.idle": "2024-12-15T18:30:33.646233Z",
          "shell.execute_reply.started": "2024-12-15T18:30:33.63466Z",
          "shell.execute_reply": "2024-12-15T18:30:33.645459Z"
        },
        "papermill": {
          "duration": 0.025994,
          "end_time": "2024-12-01T00:59:35.355548",
          "exception": false,
          "start_time": "2024-12-01T00:59:35.329554",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "dc167e61"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_apps_all_train_test(apps_all):\n",
        "    apps_all_train = apps_all[~apps_all['TARGET'].isnull()]\n",
        "    apps_all_test = apps_all[apps_all['TARGET'].isnull()]\n",
        "\n",
        "    apps_all_test = apps_all_test.drop('TARGET', axis=1)\n",
        "\n",
        "    return apps_all_train, apps_all_test\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T18:30:33.647169Z",
          "iopub.execute_input": "2024-12-15T18:30:33.647697Z",
          "iopub.status.idle": "2024-12-15T18:30:33.661911Z",
          "shell.execute_reply.started": "2024-12-15T18:30:33.647671Z",
          "shell.execute_reply": "2024-12-15T18:30:33.661148Z"
        },
        "id": "98845602-6582-4667-abfa-b03f9ed9a67c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Cross-validation with regularization\n",
        "def train_with_cross_validation(data, target):\n",
        "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
        "    auc_scores = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(folds.split(data, target)):\n",
        "        print(f\"Training fold {fold + 1}...\")\n",
        "\n",
        "        train_x, train_y = data.iloc[train_idx], target.iloc[train_idx]\n",
        "        val_x, val_y = data.iloc[val_idx], target.iloc[val_idx]\n",
        "\n",
        "        # Define the model with updated regularization\n",
        "        clf = LGBMClassifier(\n",
        "            n_estimators=2000,\n",
        "            learning_rate=0.015,\n",
        "            max_depth=13,\n",
        "            num_leaves=60,\n",
        "            colsample_bytree=0.613,\n",
        "            subsample=0.708,\n",
        "            max_bin=407,\n",
        "            reg_alpha=10,  # Updated L1 regularization\n",
        "            reg_lambda=15,  # Updated L2 regularization\n",
        "            min_child_weight=6,\n",
        "            min_child_samples=165,\n",
        "            nthread=4,\n",
        "            early_stopping_round=100\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        clf.fit(\n",
        "            train_x, train_y,\n",
        "            eval_set=[(train_x, train_y), (val_x, val_y)],\n",
        "            eval_metric='auc'\n",
        "        )\n",
        "\n",
        "        # Validate and store AUC\n",
        "        val_preds = clf.predict_proba(val_x)[:, 1]\n",
        "        fold_auc = roc_auc_score(val_y, val_preds)\n",
        "        auc_scores.append(fold_auc)\n",
        "        print(f\"Fold {fold + 1} AUC: {fold_auc:.4f}\")\n",
        "\n",
        "    print(f\"Mean AUC: {np.mean(auc_scores):.4f}, Std AUC: {np.std(auc_scores):.4f}\")\n",
        "    return clf, auc_scores\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T18:30:33.662846Z",
          "iopub.execute_input": "2024-12-15T18:30:33.663078Z",
          "iopub.status.idle": "2024-12-15T18:30:36.165186Z",
          "shell.execute_reply.started": "2024-12-15T18:30:33.663056Z",
          "shell.execute_reply": "2024-12-15T18:30:36.164219Z"
        },
        "id": "55b9c1bd-b93f-4fb8-ac98-31a291fbf4b3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Functions Created\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T18:30:36.166582Z",
          "iopub.execute_input": "2024-12-15T18:30:36.167222Z",
          "iopub.status.idle": "2024-12-15T18:30:36.172226Z",
          "shell.execute_reply.started": "2024-12-15T18:30:36.167178Z",
          "shell.execute_reply": "2024-12-15T18:30:36.171198Z"
        },
        "id": "5dd8d10f-8dc3-4723-85bd-2550e3ddecad"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# application, previous, bureau, bureau_bal\n",
        "apps_all = get_apps_all_with_all_agg(apps, prev, bureau, bureau_bal, pos_bal, install, card_bal)\n",
        "apps_all = get_apps_all_encoded(apps_all)\n",
        "\n",
        "# Prepare data\n",
        "apps_all_train, apps_all_test = get_apps_all_train_test(apps_all)\n",
        "ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
        "target_app = apps_all_train['TARGET']\n",
        "\n",
        "# Train the model with cross-validation\n",
        "final_model, auc_scores = train_with_cross_validation(ftr_app, target_app)\n",
        "\n",
        "clf = final_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T18:30:36.173578Z",
          "iopub.execute_input": "2024-12-15T18:30:36.174088Z"
        },
        "id": "9f3a5b6c-0717-4d88-b2d3-f93f3cdc452b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"../output/kaggle/working/\"\n",
        "preds = clf.predict_proba(apps_all_test.drop(['SK_ID_CURR'], axis=1))[:, 1]\n",
        "apps_all_test['TARGET'] = preds\n",
        "\n",
        "apps_all_test[['SK_ID_CURR', 'TARGET']]"
      ],
      "metadata": {
        "papermill": {
          "duration": 8.850999,
          "end_time": "2024-12-01T01:10:42.180898",
          "exception": false,
          "start_time": "2024-12-01T01:10:33.329899",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "7c7f403f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "apps_all_test[['SK_ID_CURR', 'TARGET']].to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created.\")"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.131207,
          "end_time": "2024-12-01T01:10:42.331706",
          "exception": false,
          "start_time": "2024-12-01T01:10:42.200499",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "24e5daa9"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}